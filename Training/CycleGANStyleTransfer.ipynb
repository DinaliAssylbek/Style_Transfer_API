{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Code inspired from https://www.youtube.com/watch?v=4LktBHGCNfw"
      ],
      "metadata": {
        "id": "ugS6NnNUJPBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxz3mQPXA86_",
        "outputId": "22bfbf8a-deb9-4e02-dbd8-1e32ac2232d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAMvm1HPBD90"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "import tensorflow_datasets as tfds\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtchsDvjM0nk"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wgELSnjBI_t"
      },
      "source": [
        "Data Initialization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, target_size=(256, 256)):\n",
        "    image = np.array(image)\n",
        "    return cv2.resize(image, target_size)"
      ],
      "metadata": {
        "id": "7zWAIdDy3Dvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJhwDa1iBKe1"
      },
      "outputs": [],
      "source": [
        "class PaintingPictureDataset(Dataset):\n",
        "    def __init__(self, root_painting, root_picture, transform=None):\n",
        "        self.root_painting = root_painting\n",
        "        self.root_picture = root_picture\n",
        "        self.transform = transform\n",
        "\n",
        "        self.painting_images = os.listdir(root_painting)\n",
        "        self.picture_images = os.listdir(root_picture)\n",
        "        self.length_dataset = max(len(self.painting_images), len(self.picture_images))\n",
        "        self.painting_len = len(self.painting_images)\n",
        "        self.picture_len = len(self.picture_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        painting_img = self.painting_images[index % self.painting_len]\n",
        "        picture_img = self.picture_images[index % self.picture_len]\n",
        "\n",
        "        painting_path = os.path.join(self.root_painting, painting_img)\n",
        "        picture_path = os.path.join(self.root_picture, picture_img)\n",
        "\n",
        "        painting_img = preprocess(Image.open(painting_path).convert(\"RGB\"))\n",
        "        picture_img = preprocess(Image.open(picture_path).convert(\"RGB\"))\n",
        "\n",
        "        if self.transform:\n",
        "            augmentations = self.transform(image=painting_img, image0=picture_img)\n",
        "            painting_img = augmentations[\"image\"]\n",
        "            picture_img = augmentations[\"image0\"]\n",
        "\n",
        "        return painting_img, picture_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        "    is_check_shapes=False\n",
        ")"
      ],
      "metadata": {
        "id": "mbokPxH5TeMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6ttoBCyCbMv"
      },
      "outputs": [],
      "source": [
        "dataset = PaintingPictureDataset(\"/content/drive/MyDrive/munch_paintings\", \"/content/drive/MyDrive/photo_jpg\", transform=transforms)\n",
        "# val_dataset = PaintingPictureDataset(root_horse=\"cyclegan_test/horse1\", root_zebra=\"cyclegan_test/zebra1\", transform=transforms)\n",
        "loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_BcofBpEEmv"
      },
      "source": [
        "Define Discreminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJIUQLw5EDVo"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                4,\n",
        "                stride,\n",
        "                1,\n",
        "                bias=True,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1uidKjeFhM4"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(\n",
        "                Block(in_channels, feature, stride=1 if feature == features[-1] else 2)\n",
        "            )\n",
        "            in_channels = feature\n",
        "        layers.append(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                1,\n",
        "                kernel_size=4,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            )\n",
        "        )\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        return torch.sigmoid(self.model(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc_Picture = Discriminator().to(device)\n",
        "disc_Painting = Discriminator().to(device)"
      ],
      "metadata": {
        "id": "3YmcVVD7UA9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdF6QlK0DAvt"
      },
      "source": [
        "Define Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdpL4vDMHchv"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True) if use_act else nn.Identity(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RKJ5bllHeP7"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
        "            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGWbkImOHf2X"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_channels, num_features=64, num_residuals=9):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                img_channels,\n",
        "                num_features,\n",
        "                kernel_size=7,\n",
        "                stride=1,\n",
        "                padding=3,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.InstanceNorm2d(num_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.down_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(\n",
        "                    num_features, num_features * 2, kernel_size=3, stride=2, padding=1\n",
        "                ),\n",
        "                ConvBlock(\n",
        "                    num_features * 2,\n",
        "                    num_features * 4,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(num_features * 4) for _ in range(num_residuals)]\n",
        "        )\n",
        "        self.up_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(\n",
        "                    num_features * 4,\n",
        "                    num_features * 2,\n",
        "                    down=False,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    output_padding=1,\n",
        "                ),\n",
        "                ConvBlock(\n",
        "                    num_features * 2,\n",
        "                    num_features * 1,\n",
        "                    down=False,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    output_padding=1,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.last = nn.Conv2d(\n",
        "            num_features * 1,\n",
        "            img_channels,\n",
        "            kernel_size=7,\n",
        "            stride=1,\n",
        "            padding=3,\n",
        "            padding_mode=\"reflect\",\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        for layer in self.down_blocks:\n",
        "            x = layer(x)\n",
        "        x = self.res_blocks(x)\n",
        "        for layer in self.up_blocks:\n",
        "            x = layer(x)\n",
        "        return torch.tanh(self.last(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_Painting = Generator(img_channels=3, num_residuals=9).to(device)\n",
        "gen_Picture = Generator(img_channels=3, num_residuals=9).to(device)"
      ],
      "metadata": {
        "id": "J1XsJZgKUKTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCGF3_ORUCzR"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/saved_models\""
      ],
      "metadata": {
        "id": "dL0o_Wb0dhJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CG4f5SCUCRL"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image\n",
        "def train_fn(\n",
        "    disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler\n",
        "):\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (painting, picture) in enumerate(loop):\n",
        "        painting = painting.to(device)\n",
        "        picture = picture.to(device)\n",
        "\n",
        "        # Train Discriminators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_picture = gen_H(painting)\n",
        "            D_H_real = disc_H(picture)\n",
        "            D_H_fake = disc_H(fake_picture.detach())\n",
        "            H_reals += D_H_real.mean().item()\n",
        "            H_fakes += D_H_fake.mean().item()\n",
        "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "            fake_painting = gen_Z(picture)\n",
        "            D_Z_real = disc_Z(painting)\n",
        "            D_Z_fake = disc_Z(fake_painting.detach())\n",
        "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
        "            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
        "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_H_loss + D_Z_loss) / 2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_H_fake = disc_H(fake_picture)\n",
        "            D_Z_fake = disc_Z(fake_painting)\n",
        "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_painting = gen_Z(fake_picture)\n",
        "            cycle_picture = gen_H(fake_painting)\n",
        "            cycle_painting_loss = l1(painting, cycle_painting)\n",
        "            cycle_picture_loss = l1(picture, cycle_picture)\n",
        "\n",
        "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
        "            identity_painting = gen_Z(painting)\n",
        "            identity_picture = gen_H(picture)\n",
        "            identity_painting_loss = l1(painting, identity_painting)\n",
        "            identity_picture_loss = l1(picture, identity_picture)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_Z\n",
        "                + loss_G_H\n",
        "                + cycle_painting_loss * 10\n",
        "                + cycle_picture_loss * 10\n",
        "                + identity_picture_loss * 0\n",
        "                + identity_painting_loss * 0\n",
        "            )\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 200 == 0:\n",
        "            save_image(fake_picture * 0.5 + 0.5, f\"/content/saved_images/picture_{idx}.png\")\n",
        "            save_image(fake_painting * 0.5 + 0.5, f\"/content/saved_images/painting_{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))\n",
        "        if idx % 10 == 0:\n",
        "          torch.save(gen_Painting.state_dict(), f\"{save_path}/gen_Painting.pt\")\n",
        "          torch.save(gen_Picture.state_dict(), f\"{save_path}/gen_Picture.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROybgTjSUqR5",
        "outputId": "c503460b-a169-4cb4-bc8b-951227d172e8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-4631a585a6b9>:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  g_scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-37-4631a585a6b9>:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  d_scaler = torch.cuda.amp.GradScaler()\n",
            "  0%|          | 0/7038 [00:00<?, ?it/s]<ipython-input-15-985344d54175>:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-15-985344d54175>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            " 22%|██▏       | 1528/7038 [06:58<12:37,  7.27it/s, H_fake=0.434, H_real=0.56]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7eaa983f6c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7eaa983f6c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 25%|██▌       | 1764/7038 [07:48<15:00,  5.86it/s, H_fake=0.433, H_real=0.56]<function _MultiProcessingDataLoaderIter.__del__ at 0x7eaa983f6c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7eaa983f6c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 25%|██▌       | 1765/7038 [07:48<14:24,  6.10it/s, H_fake=0.433, H_real=0.56]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7eaa983f6c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7eaa983f6c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 29%|██▉       | 2037/7038 [08:53<11:43,  7.11it/s, H_fake=0.432, H_real=0.561]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7eaa983f6c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7eaa983f6c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "100%|██████████| 7038/7038 [25:29<00:00,  4.60it/s, H_fake=0.415, H_real=0.575]\n",
            "100%|██████████| 7038/7038 [18:05<00:00,  6.49it/s, H_fake=0.383, H_real=0.605]\n",
            "100%|██████████| 7038/7038 [18:16<00:00,  6.42it/s, H_fake=0.37, H_real=0.618]\n",
            "100%|██████████| 7038/7038 [18:53<00:00,  6.21it/s, H_fake=0.362, H_real=0.628]\n",
            "100%|██████████| 7038/7038 [18:10<00:00,  6.45it/s, H_fake=0.354, H_real=0.636]\n",
            "100%|██████████| 7038/7038 [18:09<00:00,  6.46it/s, H_fake=0.345, H_real=0.646]\n",
            "100%|██████████| 7038/7038 [18:08<00:00,  6.47it/s, H_fake=0.342, H_real=0.648]\n",
            "100%|██████████| 7038/7038 [18:12<00:00,  6.44it/s, H_fake=0.345, H_real=0.644]\n",
            "100%|██████████| 7038/7038 [18:11<00:00,  6.45it/s, H_fake=0.346, H_real=0.642]\n",
            "100%|██████████| 7038/7038 [18:06<00:00,  6.48it/s, H_fake=0.347, H_real=0.644]\n"
          ]
        }
      ],
      "source": [
        "opt_disc = optim.Adam(\n",
        "        list(disc_Picture.parameters()) + list(disc_Painting.parameters()),\n",
        "        lr=1e-5,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "opt_gen = optim.Adam(\n",
        "    list(gen_Painting.parameters()) + list(gen_Picture.parameters()),\n",
        "    lr=1e-5,\n",
        "    betas=(0.5, 0.999),\n",
        ")\n",
        "\n",
        "L1 = nn.L1Loss()\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "g_scaler = torch.cuda.amp.GradScaler()\n",
        "d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(10):\n",
        "    train_fn(disc_Picture, disc_Painting, gen_Painting, gen_Picture, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler,)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
